# pages/10_comparativa.py
import streamlit as st

st.set_page_config(page_title="DWH vs Lake vs Lakehouse", page_icon="üîÑ", layout="wide")

st.markdown("<h1 style='text-align:center; color:#1e3d8f;'>üîÑ Data Warehouse vs Data Lake vs Lakehouse</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center; font-size:16px; color:gray;'>Comparativa de arquitecturas de datos modernas</p>", unsafe_allow_html=True)

st.divider()

# --- Introducci√≥n ---
st.subheader("üìù Tres Enfoques para Gesti√≥n de Datos")
st.write("""
En el ecosistema moderno de datos, existen tres arquitecturas principales que a menudo se comparan y confunden:
**Data Warehouse**, **Data Lake** y **Data Lakehouse**. Cada una tiene sus prop√≥sitos, fortalezas y casos de uso ideales.
""")

st.divider()

# --- Las Tres Arquitecturas ---
st.subheader("üèóÔ∏è Las Tres Arquitecturas")

col1, col2, col3 = st.columns(3)

with col1:
    st.info("""
    ### üè¢ Data Warehouse
    
    **Qu√© es:**
    Sistema optimizado para an√°lisis
    de datos **estructurados** e **hist√≥ricos**
    
    **Origen:** A√±os 90 (Inmon, Kimball)
    
    **Tecnolog√≠a:**
    - Base de datos relacional
    - Esquema definido (schema-on-write)
    - Modelo dimensional (estrella/copo)
    
    **Datos:**
    - Estructurados y limpios
    - ETL antes de cargar
    - Formato tabular
    
    **Ejemplos:**
    - Snowflake
    - BigQuery
    - Redshift
    - Synapse Analytics
    """)

with col2:
    st.success("""
    ### üåä Data Lake
    
    **Qu√© es:**
    Repositorio centralizado para almacenar
    datos **raw en cualquier formato**
    
    **Origen:** ~2010 (Era Big Data)
    
    **Tecnolog√≠a:**
    - Object storage (S3, ADLS, GCS)
    - Schema-on-read
    - Formatos: Parquet, JSON, CSV, logs
    
    **Datos:**
    - Estructurados, semi-estructurados, no estructurados
    - Guardados en formato original
    - Sin transformaci√≥n previa
    
    **Ejemplos:**
    - AWS S3 + Athena/Glue
    - Azure Data Lake + Synapse
    - Google Cloud Storage + Dataproc
    """)

with col3:
    st.warning("""
    ### üè† Data Lakehouse
    
    **Qu√© es:**
    Arquitectura h√≠brida que combina
    **flexibilidad de Lake** + **estructura de Warehouse**
    
    **Origen:** ~2020 (Databricks)
    
    **Tecnolog√≠a:**
    - Storage de Lake
    - ACID transactions
    - Metadata layer (Delta, Iceberg)
    
    **Datos:**
    - Todos los tipos
    - Schema enforcement opcional
    - Versionado de datos
    
    **Ejemplos:**
    - Databricks (Delta Lake)
    - Apache Iceberg
    - Apache Hudi
    """)

st.divider()

# --- Comparativa Detallada ---
st.subheader("‚öñÔ∏è Comparativa Detallada")

comparison_data = {
    "Caracter√≠stica": [
        "Tipo de datos",
        "Esquema",
        "Formato de almacenamiento",
        "Procesamiento",
        "Calidad de datos",
        "Performance consultas",
        "Costo de storage",
        "Flexibilidad",
        "Time-to-insight",
        "Governance",
        "ACID transactions",
        "Casos de uso principales"
    ],
    "üè¢ Data Warehouse": [
        "Estructurados",
        "Schema-on-write (r√≠gido)",
        "Tablas relacionales",
        "SQL",
        "Alta (ETL)",
        "Muy r√°pido (optimizado)",
        "$$ Alto",
        "Baja",
        "Lento (ETL)",
        "Fuerte",
        "‚úÖ S√≠",
        "BI, Reporting"
    ],
    "üåä Data Lake": [
        "Todos (sin l√≠mite)",
        "Schema-on-read (flexible)",
        "Archivos (Parquet, JSON)",
        "Spark, Presto, Athena",
        "Variable (datos raw)",
        "Medio-Lento",
        "$ Bajo",
        "Muy alta",
        "R√°pido (carga directa)",
        "D√©bil",
        "‚ùå No (originalmente)",
        "ML, Exploraci√≥n, Archiving"
    ],
    "üè† Data Lakehouse": [
        "Todos",
        "H√≠brido (ambos)",
        "Archivos con metadata",
        "SQL + Spark",
        "Alta (enforced)",
        "R√°pido",
        "$ Bajo-Medio",
        "Alta",
        "Medio",
        "Fuerte",
        "‚úÖ S√≠",
        "BI + ML + Exploraci√≥n"
    ]
}

st.table(comparison_data)

st.divider()

# --- Deep Dive ---
st.subheader("üîç An√°lisis Profundo")

tab1, tab2, tab3 = st.tabs(["üè¢ Data Warehouse", "üåä Data Lake", "üè† Data Lakehouse"])

with tab1:
    st.markdown("""
    ### Data Warehouse - El Cl√°sico
    
    **Historia:**
    Concepto introducido en los a√±os 90 por Bill Inmon y Ralph Kimball.
    Revolucion√≥ el an√°lisis de datos empresariales al separar OLTP de OLAP.
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("""
        **Fortalezas:**
        
        ‚úÖ **Rendimiento excepcional** para queries SQL
        - Optimizado espec√≠ficamente para an√°lisis
        - √çndices, particionamiento, compresi√≥n
        - Queries complejas en segundos
        
        ‚úÖ **Calidad de datos garantizada**
        - ETL valida y limpia antes de cargar
        - Esquema definido evita errores
        - Consistencia enforced
        
        ‚úÖ **Modelo dimensional intuitivo**
        - F√°cil de entender para analistas
        - Estrella/copo de nieve familiar
        - Herramientas BI integran perfecto
        
        ‚úÖ **Gobierno y auditor√≠a**
        - Control de acceso granular
        - Historial de cambios (SCD)
        - Compliance y regulaci√≥n
        """)
    
    with col2:
        st.error("""
        **Limitaciones:**
        
        ‚ùå **Solo datos estructurados**
        - No puede almacenar JSON variado
        - Logs, im√°genes, videos = No
        - Esquema r√≠gido
        
        ‚ùå **Rigidez del esquema**
        - Cambios requieren redise√±o ETL
        - Lento para adaptarse a cambios
        - No apto para exploraci√≥n √°gil
        
        ‚ùå **Costo**
        - Storage m√°s caro que Data Lake
        - Compute dedicado costoso
        - Licencias (on-premise)
        
        ‚ùå **Latencia de carga**
        - ETL batch (horas/d√≠as)
        - No real-time
        - Duplicaci√≥n de datos
        """)
    
    st.info("""
    **Mejor para:**
    - Reporting ejecutivo y KPIs
    - BI y dashboards empresariales
    - An√°lisis hist√≥rico de datos transaccionales
    - Cumplimiento regulatorio
    - Organizaciones maduras con datos estables
    """)

with tab2:
    st.markdown("""
    ### Data Lake - El Flexible
    
    **Historia:**
    Surgi√≥ ~2010 con el auge de Hadoop y Big Data. Promet√≠a almacenar "todos los datos" 
    a bajo costo sin necesidad de estructura previa.
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("""
        **Fortalezas:**
        
        ‚úÖ **Almacena cualquier tipo de dato**
        - Estructurado, semi-estructurado, no estructurado
        - JSON, CSV, Parquet, logs, im√°genes, videos
        - Sin l√≠mites de esquema
        
        ‚úÖ **Costo de storage muy bajo**
        - S3: ~$0.023/GB/mes
        - 10-20x m√°s barato que DWH
        - Ideal para Big Data
        
        ‚úÖ **Flexibilidad m√°xima**
        - Schema-on-read
        - Experimentaci√≥n √°gil
        - Ideal para data scientists
        
        ‚úÖ **Escalabilidad ilimitada**
        - Petabytes sin problema
        - Separaci√≥n compute/storage
        - Pay-as-you-go
        """)
    
    with col2:
        st.error("""
        **Limitaciones:**
        
        ‚ùå **"Data Swamp" (pantano de datos)**
        - Sin gobierno = caos
        - Datos duplicados/inconsistentes
        - Dif√≠cil encontrar datos √∫tiles
        
        ‚ùå **Performance pobre para BI**
        - Queries SQL lentos
        - Sin √≠ndices/optimizaci√≥n
        - Escaneo full de archivos
        
        ‚ùå **Sin ACID transactions**
        - No updates at√≥micos
        - Inconsistencias posibles
        - Dif√≠cil mantener calidad
        
        ‚ùå **Complejidad t√©cnica**
        - Requiere Spark/Presto
        - Curva de aprendizaje alta
        - No self-service para analistas
        """)
    
    st.info("""
    **Mejor para:**
    - Machine Learning (datos raw necesarios)
    - An√°lisis exploratorio de data scientists
    - Archiving de datos hist√≥ricos
    - IoT y streaming data
    - Datos no estructurados (logs, clickstream)
    """)

with tab3:
    st.markdown("""
    ### Data Lakehouse - Lo Mejor de Ambos Mundos
    
    **Historia:**
    Concepto popularizado por Databricks en 2020. Promete unificar Data Lake y Data Warehouse
    en una sola arquitectura, eliminando la necesidad de duplicar datos.
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("""
        **Fortalezas:**
        
        ‚úÖ **Unifica BI y ML**
        - Un solo lugar para todos los datos
        - SQL para BI + Spark para ML
        - No duplicaci√≥n Lake ‚Üí Warehouse
        
        ‚úÖ **ACID sobre Data Lake**
        - Delta Lake/Iceberg a√±aden transacciones
        - Updates, deletes, merges posibles
        - Versionado de datos (time travel)
        
        ‚úÖ **Performance mejorado**
        - Metadata layer optimiza queries
        - Caching inteligente
        - Mejor que Lake puro, cerca de DWH
        
        ‚úÖ **Flexibilidad + Gobierno**
        - Schema enforcement opcional
        - Governance sobre archivos
        - Calidad de datos enforced
        
        ‚úÖ **Costo reducido**
        - Storage de Lake (barato)
        - Compute solo cuando necesario
        - Sin duplicaci√≥n de datos
        """)
    
    with col2:
        st.error("""
        **Limitaciones:**
        
        ‚ùå **Tecnolog√≠a relativamente nueva**
        - Menos maduro que DWH
        - Menos herramientas integradas
        - Expertise menos com√∫n
        
        ‚ùå **Complejidad de setup**
        - Requiere configuraci√≥n cuidadosa
        - Delta Lake/Iceberg/Hudi diferentes
        - Curva de aprendizaje
        
        ‚ùå **Performance a√∫n no igual a DWH**
        - Para queries muy complejas
        - DWH dedicado sigue siendo m√°s r√°pido
        - Aunque la brecha se cierra
        
        ‚ùå **Vendor lock-in posible**
        - Delta Lake (Databricks)
        - Aunque hay open source options
        """)
    
    st.info("""
    **Mejor para:**
    - Organizaciones que quieren unificar Lake + Warehouse
    - Casos de uso de BI + ML simult√°neos
    - Empresas cloud-native modernas
    - Reducir duplicaci√≥n y costos
    - Equipos √°giles con requisitos cambiantes
    """)

st.divider()

# --- Arquitecturas en Pr√°ctica ---
st.subheader("üèóÔ∏è Arquitecturas en Pr√°ctica")

st.markdown("""
### C√≥mo se usan en el mundo real
""")

col1, col2 = st.columns(2)

with col1:
    st.warning("""
    ### Arquitectura Tradicional (Separada)
    
    ```
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Sources    ‚îÇ
    ‚îÇ  (OLTP DBs)  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ ETL
           ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Data Lake    ‚îÇ      ‚îÇ Data         ‚îÇ
    ‚îÇ (S3)         ‚îÇ ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ Warehouse    ‚îÇ
    ‚îÇ              ‚îÇ ELT  ‚îÇ (Snowflake)  ‚îÇ
    ‚îÇ - Raw data   ‚îÇ      ‚îÇ              ‚îÇ
    ‚îÇ - ML         ‚îÇ      ‚îÇ - BI/Reports ‚îÇ
    ‚îÇ - Archive    ‚îÇ      ‚îÇ - KPIs       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì                      ‚Üì
    ML/Data Science        Dashboards/BI
    ```
    
    **Pros:**
    - Especializaci√≥n (cada uno optimizado)
    - Herramientas maduras
    
    **Cons:**
    - Duplicaci√≥n de datos
    - Dos sistemas que mantener
    - Sincronizaci√≥n necesaria
    """)

with col2:
    st.success("""
    ### Arquitectura Lakehouse (Unificada)
    
    ```
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Sources    ‚îÇ
    ‚îÇ  (OLTP DBs)  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ Ingestion
           ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ      Data Lakehouse          ‚îÇ
    ‚îÇ      (Databricks)            ‚îÇ
    ‚îÇ                              ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
    ‚îÇ  ‚îÇ  Raw   ‚îÇ ‚Üí ‚îÇ Curated   ‚îÇ ‚îÇ
    ‚îÇ  ‚îÇ(Bronze)‚îÇ   ‚îÇ (Silver)  ‚îÇ ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
    ‚îÇ                     ‚Üì        ‚îÇ
    ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
    ‚îÇ              ‚îÇ Analytics ‚îÇ  ‚îÇ
    ‚îÇ              ‚îÇ  (Gold)   ‚îÇ  ‚îÇ
    ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚Üì
         BI Tools + ML Notebooks
    ```
    
    **Pros:**
    - Un solo sistema
    - No duplicaci√≥n
    - BI y ML sobre mismos datos
    
    **Cons:**
    - Menos maduro
    - Requiere expertise
    """)

st.divider()

# --- Migraci√≥n ---
st.subheader("üîÑ Rutas de Migraci√≥n")

st.markdown("""
### ¬øC√≥mo evolucionar tu arquitectura?
""")

tab1, tab2, tab3 = st.tabs(["DWH ‚Üí Lakehouse", "Lake ‚Üí Lakehouse", "H√≠brido"])

with tab1:
    st.code("""
Migraci√≥n: Data Warehouse ‚Üí Data Lakehouse

Paso 1: Agregar Data Lake
‚îú‚îÄ Mantener DWH existente (no apagar)
‚îú‚îÄ Crear Data Lake (S3/ADLS)
‚îî‚îÄ Cargar datos raw al Lake

Paso 2: Implementar Lakehouse layer
‚îú‚îÄ Delta Lake/Iceberg sobre el Lake
‚îú‚îÄ Migrar transformaciones ETL ‚Üí ELT (dbt)
‚îî‚îÄ Validar performance

Paso 3: Migraci√≥n gradual de casos de uso
‚îú‚îÄ Empezar con casos de uso nuevos
‚îú‚îÄ Migrar reportes menos cr√≠ticos
‚îî‚îÄ Finalmente, reportes ejecutivos

Paso 4: Deprecar DWH
‚îú‚îÄ Solo cuando todo migrado y validado
‚îú‚îÄ Mantener per√≠odo de rollback posible
‚îî‚îÄ Liberar recursos del DWH antiguo

Timeline t√≠pico: 12-18 meses
Risk: Medio-Alto
Beneficio: Reducci√≥n costos 30-50%
    """)

with tab2:
    st.code("""
Migraci√≥n: Data Lake ‚Üí Data Lakehouse

Paso 1: Implementar metadata layer
‚îú‚îÄ Instalar Delta Lake/Iceberg
‚îú‚îÄ Convertir Parquet ‚Üí Delta format
‚îî‚îÄ No cambiar ubicaci√≥n de datos

Paso 2: Agregar schema enforcement
‚îú‚îÄ Definir esquemas para tablas principales
‚îú‚îÄ Implementar validaciones de calidad
‚îî‚îÄ Habilitar ACID transactions

Paso 3: Optimizar para queries
‚îú‚îÄ Clustering y partitioning
‚îú‚îÄ Z-ordering (Delta)
‚îú‚îÄ Compaction de archivos peque√±os

Paso 4: Conectar herramientas BI
‚îú‚îÄ Tableau/Power BI sobre Lakehouse
‚îú‚îÄ Crear vistas materializadas
‚îî‚îÄ Habilitar SQL endpoint

Timeline t√≠pico: 3-6 meses
Risk: Bajo
Beneficio: Habilitar BI sin duplicar datos
    """)

with tab3:
    st.code("""
Enfoque H√≠brido (mejor para muchos)

Arquitectura:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Sources   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Data Lakehouse (Unified)    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   Raw   ‚îÇ‚Üí ‚îÇ   Curated    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ (Bronze)‚îÇ  ‚îÇ   (Silver)   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                                ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   DWH   ‚îÇ                    ‚îÇ ML/Data  ‚îÇ
    ‚îÇ (Legacy)‚îÇ                    ‚îÇ Science  ‚îÇ
    ‚îÇ         ‚îÇ                    ‚îÇ          ‚îÇ
    ‚îÇ Reportes‚îÇ                    ‚îÇ Notebooks‚îÇ
    ‚îÇ cr√≠ticos‚îÇ                    ‚îÇ Spark    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Estrategia:
‚îú‚îÄ Lakehouse para nuevos use cases
‚îú‚îÄ DWH mantiene reportes cr√≠ticos legacy
‚îú‚îÄ Migraci√≥n gradual seg√∫n ROI
‚îî‚îÄ Ambos coexisten largo plazo

Ventaja: Minimiza riesgo, maximiza beneficios
    """)

st.divider()

# --- Casos de Uso ---
st.subheader("üéØ Qu√© Usar Cu√°ndo")

cases = {
    "Caso de Uso": [
        "Reportes ejecutivos (dashboards)",
        "KPIs y m√©tricas de negocio",
        "An√°lisis financiero/compliance",
        "Machine Learning",
        "Exploraci√≥n de datos (data scientists)",
        "Almacenamiento logs/clickstream",
        "An√°lisis en tiempo real",
        "Datos hist√≥ricos (archiving)",
        "An√°lisis ad-hoc por analistas",
        "BI self-service"
    ],
    "üè¢ DWH": ["‚úÖ Ideal", "‚úÖ Ideal", "‚úÖ Ideal", "‚ùå No", "‚ö†Ô∏è Limitado", "‚ùå No", "‚ùå No", "‚úÖ S√≠", "‚úÖ S√≠", "‚úÖ Ideal"],
    "üåä Lake": ["‚ùå Lento", "‚ùå Lento", "‚ö†Ô∏è Posible", "‚úÖ Ideal", "‚úÖ Ideal", "‚úÖ Ideal", "‚úÖ S√≠ (Streaming)", "‚úÖ Ideal", "‚úÖ S√≠", "‚ùå Dif√≠cil"],
    "üè† Lakehouse": ["‚úÖ Bien", "‚úÖ Bien", "‚úÖ Bien", "‚úÖ Ideal", "‚úÖ Ideal", "‚úÖ Ideal", "‚úÖ S√≠", "‚úÖ Ideal", "‚úÖ Ideal", "‚úÖ Bien"]
}

st.table(cases)

st.divider()

# --- Recomendaci√≥n ---
st.subheader("üí° Recomendaci√≥n Final")

col1, col2, col3 = st.columns(3)

with col1:
    st.info("""
    ### Elige DWH si...
    
    ‚úÖ Tu organizaci√≥n es madura
    
    ‚úÖ Datos son 100% estructurados
    
    ‚úÖ BI/Reporting es el 90% de uso
    
    ‚úÖ Performance cr√≠tico
    
    ‚úÖ Ya tienes DWH y funciona bien
    
    **Ejemplos:** Banca, retail tradicional
    """)

with col2:
    st.success("""
    ### Elige Lakehouse si...
    
    ‚úÖ Necesitas BI + ML
    
    ‚úÖ Datos estructurados + no estructurados
    
    ‚úÖ Cloud-native
    
    ‚úÖ Quieres reducir duplicaci√≥n
    
    ‚úÖ Flexibilidad importante
    
    **Ejemplos:** Tech companies, startups
    """)

with col3:
    st.warning("""
    ### Usa ambos (h√≠brido) si...
    
    ‚úÖ Gran empresa con legacy
    
    ‚úÖ No puedes migrar todo ya
    
    ‚úÖ Riesgo debe ser m√≠nimo
    
    ‚úÖ Casos de uso muy diversos
    
    ‚úÖ Transici√≥n gradual necesaria
    
    **Ejemplos:** Fortune 500 migrando
    """)

st.success("""
**üí° Tendencia 2025:**

El futuro es **Lakehouse** para la mayor√≠a de organizaciones nuevas.  
Para empresas existentes, un **enfoque h√≠brido** minimiza riesgo mientras se moderniza.  
Data Warehouses tradicionales no desaparecen, pero su rol se especializa.
""")

st.divider()

