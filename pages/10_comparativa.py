# pages/10_comparativa.py
import streamlit as st

st.set_page_config(page_title="DWH vs Lake vs Lakehouse", page_icon="ğŸ”„", layout="wide")

st.markdown("<h1 style='text-align:center; color:#1e3d8f;'>ğŸ”„ Data Warehouse vs Data Lake vs Lakehouse</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center; font-size:16px; color:gray;'>Comparativa de arquitecturas de datos modernas</p>", unsafe_allow_html=True)

st.divider()

# --- IntroducciÃ³n ---
st.subheader("ğŸ“ Tres Enfoques para GestiÃ³n de Datos")
st.write("""
En el ecosistema moderno de datos, existen tres arquitecturas principales que a menudo se comparan y confunden:
**Data Warehouse**, **Data Lake** y **Data Lakehouse**. Cada una tiene sus propÃ³sitos, fortalezas y casos de uso ideales.
""")

st.divider()

# --- Las Tres Arquitecturas ---
st.subheader("ğŸ—ï¸ Las Tres Arquitecturas")

col1, col2, col3 = st.columns(3)

with col1:
    st.info("""
    ### ğŸ¢ Data Warehouse
    
    **QuÃ© es:**
    Sistema optimizado para anÃ¡lisis
    de datos **estructurados** e **histÃ³ricos**
    
    **Origen:** AÃ±os 90 (Inmon, Kimball)
    
    **TecnologÃ­a:**
    - Base de datos relacional
    - Esquema definido (schema-on-write)
    - Modelo dimensional (estrella/copo)
    
    **Datos:**
    - Estructurados y limpios
    - ETL antes de cargar
    - Formato tabular
    
    **Ejemplos:**
    - Snowflake
    - BigQuery
    - Redshift
    - Synapse Analytics
    """)

with col2:
    st.success("""
    ### ğŸŒŠ Data Lake
    
    **QuÃ© es:**
    Repositorio centralizado para almacenar
    datos **raw en cualquier formato**
    
    **Origen:** ~2010 (Era Big Data)
    
    **TecnologÃ­a:**
    - Object storage (S3, ADLS, GCS)
    - Schema-on-read
    - Formatos: Parquet, JSON, CSV, logs
    
    **Datos:**
    - Estructurados, semi-estructurados, no estructurados
    - Guardados en formato original
    - Sin transformaciÃ³n previa
    
    **Ejemplos:**
    - AWS S3 + Athena/Glue
    - Azure Data Lake + Synapse
    - Google Cloud Storage + Dataproc
    """)

with col3:
    st.warning("""
    ### ğŸ  Data Lakehouse
    
    **QuÃ© es:**
    Arquitectura hÃ­brida que combina
    **flexibilidad de Lake** + **estructura de Warehouse**
    
    **Origen:** ~2020 (Databricks)
    
    **TecnologÃ­a:**
    - Storage de Lake
    - ACID transactions
    - Metadata layer (Delta, Iceberg)
    
    **Datos:**
    - Todos los tipos
    - Schema enforcement opcional
    - Versionado de datos
    
    **Ejemplos:**
    - Databricks (Delta Lake)
    - Apache Iceberg
    - Apache Hudi
    """)

st.divider()

# --- Comparativa Detallada ---
st.subheader("âš–ï¸ Comparativa Detallada")

comparison_data = {
    "CaracterÃ­stica": [
        "Tipo de datos",
        "Esquema",
        "Formato de almacenamiento",
        "Procesamiento",
        "Calidad de datos",
        "Performance consultas",
        "Costo de storage",
        "Flexibilidad",
        "Time-to-insight",
        "Governance",
        "ACID transactions",
        "Casos de uso principales"
    ],
    "ğŸ¢ Data Warehouse": [
        "Estructurados",
        "Schema-on-write (rÃ­gido)",
        "Tablas relacionales",
        "SQL",
        "Alta (ETL)",
        "Muy rÃ¡pido (optimizado)",
        "$$ Alto",
        "Baja",
        "Lento (ETL)",
        "Fuerte",
        "âœ… SÃ­",
        "BI, Reporting"
    ],
    "ğŸŒŠ Data Lake": [
        "Todos (sin lÃ­mite)",
        "Schema-on-read (flexible)",
        "Archivos (Parquet, JSON)",
        "Spark, Presto, Athena",
        "Variable (datos raw)",
        "Medio-Lento",
        "$ Bajo",
        "Muy alta",
        "RÃ¡pido (carga directa)",
        "DÃ©bil",
        "âŒ No (originalmente)",
        "ML, ExploraciÃ³n, Archiving"
    ],
    "ğŸ  Data Lakehouse": [
        "Todos",
        "HÃ­brido (ambos)",
        "Archivos con metadata",
        "SQL + Spark",
        "Alta (enforced)",
        "RÃ¡pido",
        "$ Bajo-Medio",
        "Alta",
        "Medio",
        "Fuerte",
        "âœ… SÃ­",
        "BI + ML + ExploraciÃ³n"
    ]
}

st.table(comparison_data)

st.divider()

# --- Deep Dive ---
st.subheader("ğŸ” AnÃ¡lisis Profundo")

tab1, tab2, tab3 = st.tabs(["ğŸ¢ Data Warehouse", "ğŸŒŠ Data Lake", "ğŸ  Data Lakehouse"])

with tab1:
    st.markdown("""
    ### Data Warehouse - El ClÃ¡sico
    
    **Historia:**
    Concepto introducido en los aÃ±os 90 por Bill Inmon y Ralph Kimball.
    RevolucionÃ³ el anÃ¡lisis de datos empresariales al separar OLTP de OLAP.
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("""
        **Fortalezas:**
        
        âœ… **Rendimiento excepcional** para queries SQL
        - Optimizado especÃ­ficamente para anÃ¡lisis
        - Ãndices, particionamiento, compresiÃ³n
        - Queries complejas en segundos
        
        âœ… **Calidad de datos garantizada**
        - ETL valida y limpia antes de cargar
        - Esquema definido evita errores
        - Consistencia enforced
        
        âœ… **Modelo dimensional intuitivo**
        - FÃ¡cil de entender para analistas
        - Estrella/copo de nieve familiar
        - Herramientas BI integran perfecto
        
        âœ… **Gobierno y auditorÃ­a**
        - Control de acceso granular
        - Historial de cambios (SCD)
        - Compliance y regulaciÃ³n
        """)
    
    with col2:
        st.error("""
        **Limitaciones:**
        
        âŒ **Solo datos estructurados**
        - No puede almacenar JSON variado
        - Logs, imÃ¡genes, videos = No
        - Esquema rÃ­gido
        
        âŒ **Rigidez del esquema**
        - Cambios requieren rediseÃ±o ETL
        - Lento para adaptarse a cambios
        - No apto para exploraciÃ³n Ã¡gil
        
        âŒ **Costo**
        - Storage mÃ¡s caro que Data Lake
        - Compute dedicado costoso
        - Licencias (on-premise)
        
        âŒ **Latencia de carga**
        - ETL batch (horas/dÃ­as)
        - No real-time
        - DuplicaciÃ³n de datos
        """)
    
    st.info("""
    **Mejor para:**
    - Reporting ejecutivo y KPIs
    - BI y dashboards empresariales
    - AnÃ¡lisis histÃ³rico de datos transaccionales
    - Cumplimiento regulatorio
    - Organizaciones maduras con datos estables
    """)

with tab2:
    st.markdown("""
    ### Data Lake - El Flexible
    
    **Historia:**
    SurgiÃ³ ~2010 con el auge de Hadoop y Big Data. PrometÃ­a almacenar "todos los datos" 
    a bajo costo sin necesidad de estructura previa.
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("""
        **Fortalezas:**
        
        âœ… **Almacena cualquier tipo de dato**
        - Estructurado, semi-estructurado, no estructurado
        - JSON, CSV, Parquet, logs, imÃ¡genes, videos
        - Sin lÃ­mites de esquema
        
        âœ… **Costo de storage muy bajo**
        - S3: ~$0.023/GB/mes
        - 10-20x mÃ¡s barato que DWH
        - Ideal para Big Data
        
        âœ… **Flexibilidad mÃ¡xima**
        - Schema-on-read
        - ExperimentaciÃ³n Ã¡gil
        - Ideal para data scientists
        
        âœ… **Escalabilidad ilimitada**
        - Petabytes sin problema
        - SeparaciÃ³n compute/storage
        - Pay-as-you-go
        """)
    
    with col2:
        st.error("""
        **Limitaciones:**
        
        âŒ **"Data Swamp" (pantano de datos)**
        - Sin gobierno = caos
        - Datos duplicados/inconsistentes
        - DifÃ­cil encontrar datos Ãºtiles
        
        âŒ **Performance pobre para BI**
        - Queries SQL lentos
        - Sin Ã­ndices/optimizaciÃ³n
        - Escaneo full de archivos
        
        âŒ **Sin ACID transactions**
        - No updates atÃ³micos
        - Inconsistencias posibles
        - DifÃ­cil mantener calidad
        
        âŒ **Complejidad tÃ©cnica**
        - Requiere Spark/Presto
        - Curva de aprendizaje alta
        - No self-service para analistas
        """)
    
    st.info("""
    **Mejor para:**
    - Machine Learning (datos raw necesarios)
    - AnÃ¡lisis exploratorio de data scientists
    - Archiving de datos histÃ³ricos
    - IoT y streaming data
    - Datos no estructurados (logs, clickstream)
    """)

with tab3:
    st.markdown("""
    ### Data Lakehouse - Lo Mejor de Ambos Mundos
    
    **Historia:**
    Concepto popularizado por Databricks en 2020. Promete unificar Data Lake y Data Warehouse
    en una sola arquitectura, eliminando la necesidad de duplicar datos.
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("""
        **Fortalezas:**
        
        âœ… **Unifica BI y ML**
        - Un solo lugar para todos los datos
        - SQL para BI + Spark para ML
        - No duplicaciÃ³n Lake â†’ Warehouse
        
        âœ… **ACID sobre Data Lake**
        - Delta Lake/Iceberg aÃ±aden transacciones
        - Updates, deletes, merges posibles
        - Versionado de datos (time travel)
        
        âœ… **Performance mejorado**
        - Metadata layer optimiza queries
        - Caching inteligente
        - Mejor que Lake puro, cerca de DWH
        
        âœ… **Flexibilidad + Gobierno**
        - Schema enforcement opcional
        - Governance sobre archivos
        - Calidad de datos enforced
        
        âœ… **Costo reducido**
        - Storage de Lake (barato)
        - Compute solo cuando necesario
        - Sin duplicaciÃ³n de datos
        """)
    
    with col2:
        st.error("""
        **Limitaciones:**
        
        âŒ **TecnologÃ­a relativamente nueva**
        - Menos maduro que DWH
        - Menos herramientas integradas
        - Expertise menos comÃºn
        
        âŒ **Complejidad de setup**
        - Requiere configuraciÃ³n cuidadosa
        - Delta Lake/Iceberg/Hudi diferentes
        - Curva de aprendizaje
        
        âŒ **Performance aÃºn no igual a DWH**
        - Para queries muy complejas
        - DWH dedicado sigue siendo mÃ¡s rÃ¡pido
        - Aunque la brecha se cierra
        
        âŒ **Vendor lock-in posible**
        - Delta Lake (Databricks)
        - Aunque hay open source options
        """)
    
    st.info("""
    **Mejor para:**
    - Organizaciones que quieren unificar Lake + Warehouse
    - Casos de uso de BI + ML simultÃ¡neos
    - Empresas cloud-native modernas
    - Reducir duplicaciÃ³n y costos
    - Equipos Ã¡giles con requisitos cambiantes
    """)

st.divider()

# --- Arquitecturas en PrÃ¡ctica ---
st.subheader("ğŸ—ï¸ Arquitecturas en PrÃ¡ctica")

st.markdown("""
### CÃ³mo se usan en el mundo real
""")

col1, col2 = st.columns(2)

with col1:
    st.warning("""
    ### Arquitectura Tradicional (Separada)
    
    ```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Sources    â”‚
    â”‚  (OLTP DBs)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ ETL
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Data Lake    â”‚      â”‚ Data         â”‚
    â”‚ (S3)         â”‚ â”€â”€â”€â†’ â”‚ Warehouse    â”‚
    â”‚              â”‚ ELT  â”‚ (Snowflake)  â”‚
    â”‚ - Raw data   â”‚      â”‚              â”‚
    â”‚ - ML         â”‚      â”‚ - BI/Reports â”‚
    â”‚ - Archive    â”‚      â”‚ - KPIs       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“                      â†“
    ML/Data Science        Dashboards/BI
    ```
    
    **Pros:**
    - EspecializaciÃ³n (cada uno optimizado)
    - Herramientas maduras
    
    **Cons:**
    - DuplicaciÃ³n de datos
    - Dos sistemas que mantener
    - SincronizaciÃ³n necesaria
    """)

with col2:
    st.success("""
    ### Arquitectura Lakehouse (Unificada)
    
    ```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Sources    â”‚
    â”‚  (OLTP DBs)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Ingestion
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      Data Lakehouse          â”‚
    â”‚      (Databricks)            â”‚
    â”‚                              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚  â”‚  Raw   â”‚ â†’ â”‚ Curated   â”‚ â”‚
    â”‚  â”‚(Bronze)â”‚   â”‚ (Silver)  â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚                     â†“        â”‚
    â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚              â”‚ Analytics â”‚  â”‚
    â”‚              â”‚  (Gold)   â”‚  â”‚
    â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
         BI Tools + ML Notebooks
    ```
    
    **Pros:**
    - Un solo sistema
    - No duplicaciÃ³n
    - BI y ML sobre mismos datos
    
    **Cons:**
    - Menos maduro
    - Requiere expertise
    """)

st.divider()

# --- MigraciÃ³n ---
st.subheader("ğŸ”„ Rutas de MigraciÃ³n")

st.markdown("""
### Â¿CÃ³mo evolucionar tu arquitectura?
""")

tab1, tab2, tab3 = st.tabs(["DWH â†’ Lakehouse", "Lake â†’ Lakehouse", "HÃ­brido"])

with tab1:
    st.code("""
MigraciÃ³n: Data Warehouse â†’ Data Lakehouse

Paso 1: Agregar Data Lake
â”œâ”€ Mantener DWH existente (no apagar)
â”œâ”€ Crear Data Lake (S3/ADLS)
â””â”€ Cargar datos raw al Lake

Paso 2: Implementar Lakehouse layer
â”œâ”€ Delta Lake/Iceberg sobre el Lake
â”œâ”€ Migrar transformaciones ETL â†’ ELT (dbt)
â””â”€ Validar performance

Paso 3: MigraciÃ³n gradual de casos de uso
â”œâ”€ Empezar con casos de uso nuevos
â”œâ”€ Migrar reportes menos crÃ­ticos
â””â”€ Finalmente, reportes ejecutivos

Paso 4: Deprecar DWH
â”œâ”€ Solo cuando todo migrado y validado
â”œâ”€ Mantener perÃ­odo de rollback posible
â””â”€ Liberar recursos del DWH antiguo

Timeline tÃ­pico: 12-18 meses
Risk: Medio-Alto
Beneficio: ReducciÃ³n costos 30-50%
    """)

with tab2:
    st.code("""
MigraciÃ³n: Data Lake â†’ Data Lakehouse

Paso 1: Implementar metadata layer
â”œâ”€ Instalar Delta Lake/Iceberg
â”œâ”€ Convertir Parquet â†’ Delta format
â””â”€ No cambiar ubicaciÃ³n de datos

Paso 2: Agregar schema enforcement
â”œâ”€ Definir esquemas para tablas principales
â”œâ”€ Implementar validaciones de calidad
â””â”€ Habilitar ACID transactions

Paso 3: Optimizar para queries
â”œâ”€ Clustering y partitioning
â”œâ”€ Z-ordering (Delta)
â”œâ”€ Compaction de archivos pequeÃ±os

Paso 4: Conectar herramientas BI
â”œâ”€ Tableau/Power BI sobre Lakehouse
â”œâ”€ Crear vistas materializadas
â””â”€ Habilitar SQL endpoint

Timeline tÃ­pico: 3-6 meses
Risk: Bajo
Beneficio: Habilitar BI sin duplicar datos
    """)

with tab3:
    st.code("""
Enfoque HÃ­brido (mejor para muchos)

Arquitectura:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sources   â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Data Lakehouse (Unified)    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Raw   â”‚â†’ â”‚   Curated    â”‚ â”‚
â”‚  â”‚ (Bronze)â”‚  â”‚   (Silver)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚   DWH   â”‚                    â”‚ ML/Data  â”‚
    â”‚ (Legacy)â”‚                    â”‚ Science  â”‚
    â”‚         â”‚                    â”‚          â”‚
    â”‚ Reportesâ”‚                    â”‚ Notebooksâ”‚
    â”‚ crÃ­ticosâ”‚                    â”‚ Spark    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Estrategia:
â”œâ”€ Lakehouse para nuevos use cases
â”œâ”€ DWH mantiene reportes crÃ­ticos legacy
â”œâ”€ MigraciÃ³n gradual segÃºn ROI
â””â”€ Ambos coexisten largo plazo

Ventaja: Minimiza riesgo, maximiza beneficios
    """)

st.divider()

# --- Casos de Uso ---
st.subheader("ğŸ¯ QuÃ© Usar CuÃ¡ndo")

cases = {
    "Caso de Uso": [
        "Reportes ejecutivos (dashboards)",
        "KPIs y mÃ©tricas de negocio",
        "AnÃ¡lisis financiero/compliance",
        "Machine Learning",
        "ExploraciÃ³n de datos (data scientists)",
        "Almacenamiento logs/clickstream",
        "AnÃ¡lisis en tiempo real",
        "Datos histÃ³ricos (archiving)",
        "AnÃ¡lisis ad-hoc por analistas",
        "BI self-service"
    ],
    "ğŸ¢ DWH": ["âœ… Ideal", "âœ… Ideal", "âœ… Ideal", "âŒ No", "âš ï¸ Limitado", "âŒ No", "âŒ No", "âœ… SÃ­", "âœ… SÃ­", "âœ… Ideal"],
    "ğŸŒŠ Lake": ["âŒ Lento", "âŒ Lento", "âš ï¸ Posible", "âœ… Ideal", "âœ… Ideal", "âœ… Ideal", "âœ… SÃ­ (Streaming)", "âœ… Ideal", "âœ… SÃ­", "âŒ DifÃ­cil"],
    "ğŸ  Lakehouse": ["âœ… Bien", "âœ… Bien", "âœ… Bien", "âœ… Ideal", "âœ… Ideal", "âœ… Ideal", "âœ… SÃ­", "âœ… Ideal", "âœ… Ideal", "âœ… Bien"]
}

st.table(cases)

st.divider()

# --- RecomendaciÃ³n ---
st.subheader("ğŸ’¡ RecomendaciÃ³n Final")

col1, col2, col3 = st.columns(3)

with col1:
    st.info("""
    ### Elige DWH si...
    
    âœ… Tu organizaciÃ³n es madura
    
    âœ… Datos son 100% estructurados
    
    âœ… BI/Reporting es el 90% de uso
    
    âœ… Performance crÃ­tico
    
    âœ… Ya tienes DWH y funciona bien
    
    **Ejemplos:** Banca, retail tradicional
    """)

with col2:
    st.success("""
    ### Elige Lakehouse si...
    
    âœ… Necesitas BI + ML
    
    âœ… Datos estructurados + no estructurados
    
    âœ… Cloud-native
    
    âœ… Quieres reducir duplicaciÃ³n
    
    âœ… Flexibilidad importante
    
    **Ejemplos:** Tech companies, startups
    """)

with col3:
    st.warning("""
    ### Usa ambos (hÃ­brido) si...
    
    âœ… Gran empresa con legacy
    
    âœ… No puedes migrar todo ya
    
    âœ… Riesgo debe ser mÃ­nimo
    
    âœ… Casos de uso muy diversos
    
    âœ… TransiciÃ³n gradual necesaria
    
    **Ejemplos:** Fortune 500 migrando
    """)

st.success("""
**ğŸ’¡ Tendencia 2025:**

El futuro es **Lakehouse** para la mayorÃ­a de organizaciones nuevas.  
Para empresas existentes, un **enfoque hÃ­brido** minimiza riesgo mientras se moderniza.  
Data Warehouses tradicionales no desaparecen, pero su rol se especializa.
""")

st.divider()

