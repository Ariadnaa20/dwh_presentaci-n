# pages/8_rendimento.py
import streamlit as st

st.set_page_config(page_title="Rendimiento DWH", page_icon="‚ö°", layout="wide")

st.markdown("<h1 style='text-align:center; color:#1e3d8f;'>‚ö° Optimizaci√≥n de Rendimiento</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center; font-size:16px; color:gray;'>Particiones, √≠ndices y t√©cnicas para acelerar consultas</p>", unsafe_allow_html=True)

st.divider()

# --- Introducci√≥n ---
st.subheader("üìù ¬øPor qu√© es crucial el rendimiento en DWH?")
st.write("""
Un **Data Warehouse** puede contener **terabytes o petabytes** de datos. Sin optimizaci√≥n adecuada,
las consultas pueden tardar horas en ejecutarse. Las t√©cnicas de optimizaci√≥n son esenciales para:
- Respuestas en segundos vs horas
- Experiencia de usuario √°gil
- Reducci√≥n de costos de compute
- Escalabilidad sostenible
""")

st.divider()

# --- T√©cnicas Principales ---
st.subheader("üéØ T√©cnicas Principales de Optimizaci√≥n")

# Particionamiento
with st.expander("üìÇ Particionamiento (Partitioning)"):
    st.markdown("""
    ### ¬øQu√© es el Particionamiento?
    
    **Particionamiento** divide una tabla grande en fragmentos m√°s peque√±os basados en valores de columnas espec√≠ficas.
    Cada partici√≥n se almacena y gestiona independientemente.
    """)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        **Tipos de Particionamiento:**
        
        **1. Particionamiento por Rango (Range Partitioning)**
        - M√°s com√∫n en DWH
        - Basado en fechas t√≠picamente
        - Ejemplo: Una partici√≥n por d√≠a/mes/a√±o
        
        **2. Particionamiento por Lista (List Partitioning)**
        - Basado en valores discretos
        - Ejemplo: Por pa√≠s, regi√≥n, categor√≠a
        
        **3. Particionamiento por Hash**
        - Distribuci√≥n uniforme
        - √ötil para balanceo de carga
        
        **4. Particionamiento Compuesto**
        - Combina m√∫ltiples estrategias
        - Ejemplo: Por a√±o + por regi√≥n
        """)
    
    with col2:
        st.code("""
-- Ejemplo PostgreSQL
CREATE TABLE ventas (
    fecha DATE,
    producto_id INT,
    cantidad INT,
    importe DECIMAL
)
PARTITION BY RANGE (fecha);

-- Particiones mensuales
CREATE TABLE ventas_2024_01
PARTITION OF ventas
FOR VALUES FROM ('2024-01-01') 
TO ('2024-02-01');

CREATE TABLE ventas_2024_02
PARTITION OF ventas
FOR VALUES FROM ('2024-02-01') 
TO ('2024-03-01');
        """, language="sql")
    
    st.success("""
    **Ventajas del Particionamiento:**
    
    ‚úÖ **Partition Pruning:** Solo escanea particiones relevantes
    - Query: `WHERE fecha = '2024-01-15'` ‚Üí Solo escanea partici√≥n enero
    - Mejora rendimiento 10x-100x en queries con filtros de fecha
    
    ‚úÖ **Mantenimiento m√°s f√°cil:**
    - Eliminar datos antiguos: DROP partition (instant√°neo vs DELETE lento)
    - Backup/restore por partici√≥n
    
    ‚úÖ **Paralelismo:**
    - Consultas pueden ejecutarse en paralelo por partici√≥n
    
    ‚úÖ **Gesti√≥n de almacenamiento:**
    - Particiones antiguas en storage m√°s barato
    - Compresi√≥n diferenciada
    """)
    
    st.warning("""
    **Consideraciones:**
    
    ‚ö†Ô∏è Elegir columna de partici√≥n correcta (usualmente fecha)
    
    ‚ö†Ô∏è Demasiadas particiones = overhead de metadatos
    
    ‚ö†Ô∏è Consultas sin filtro de partici√≥n escanean todo
    """)

# √çndices
with st.expander("üîç √çndices (Indexes)"):
    st.markdown("""
    ### √çndices en Data Warehouses
    
    **√çndices** aceleran b√∫squedas al crear estructuras de datos auxiliares que permiten acceso r√°pido.
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **Tipos de √çndices:**
        
        **1. B-Tree Index (Tradicional)**
        - Para b√∫squedas exactas y rangos
        - √ötil en dimensiones
        - WHERE, JOIN, ORDER BY
        
        **2. Bitmap Index**
        - Ideal para DWH
        - Columnas con baja cardinalidad
        - Muy eficiente para AND/OR/NOT
        - Ejemplo: g√©nero (M/F), estado (activo/inactivo)
        
        **3. Columnstore Index**
        - Almacenamiento columnar
        - Compresi√≥n excelente
        - Perfecto para agregaciones
        - Usado en SQL Server, Synapse
        
        **4. Covering Index**
        - Incluye todas las columnas necesarias
        - Evita acceso a tabla principal
        - Index-only scan
        """)
    
    with col2:
        st.code("""
-- B-Tree index
CREATE INDEX idx_cliente_id 
ON fact_ventas(cliente_id);

-- Bitmap index (Oracle)
CREATE BITMAP INDEX idx_estado 
ON dim_cliente(estado);

-- Columnstore (SQL Server)
CREATE COLUMNSTORE INDEX idx_cs_ventas
ON fact_ventas;

-- Covering index
CREATE INDEX idx_fecha_producto_amount
ON fact_ventas(fecha, producto_id)
INCLUDE (cantidad, importe);
        """, language="sql")
    
    st.info("""
    **Cu√°ndo usar √≠ndices:**
    
    ‚úÖ Columnas frecuentemente en WHERE
    
    ‚úÖ Columnas de JOIN
    
    ‚úÖ Dimensiones (tablas peque√±as)
    
    ‚úÖ Claves for√°neas en tablas de hechos
    
    **Cu√°ndo NO usar √≠ndices:**
    
    ‚ùå Tablas de hechos con full table scans frecuentes
    
    ‚ùå Columnas que cambian constantemente
    
    ‚ùå √çndices que no se usan (overhead en writes)
    """)

# Clustering
with st.expander("üóÇÔ∏è Clustering (Ordenamiento f√≠sico)"):
    st.markdown("""
    ### Clustering Keys
    
    **Clustering** ordena f√≠sicamente los datos en disco seg√∫n columnas espec√≠ficas.
    Similar a particionamiento pero m√°s granular.
    """)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        **C√≥mo funciona:**
        - Los datos se ordenan f√≠sicamente en storage
        - Mejora la localidad de datos
        - Reduce I/O al leer datos relacionados
        
        **Especialmente √∫til en:**
        - Snowflake (micro-partitions autom√°ticas)
        - BigQuery (clustering columns)
        - Redshift (sort keys)
        
        **Beneficios:**
        - Partition pruning m√°s efectivo
        - Compresi√≥n mejorada (datos similares juntos)
        - Queries con filtros m√°s r√°pidas
        """)
    
    with col2:
        st.code("""
-- Snowflake
CREATE TABLE ventas (
    fecha DATE,
    region VARCHAR,
    importe NUMBER
)
CLUSTER BY (fecha, region);

-- BigQuery
CREATE TABLE `project.dataset.ventas`
PARTITION BY DATE(fecha)
CLUSTER BY region, categoria;

-- Redshift
CREATE TABLE ventas (
    fecha DATE,
    producto_id INT,
    importe DECIMAL
)
SORTKEY (fecha, producto_id);
        """, language="sql")

# Compresi√≥n
with st.expander("üì¶ Compresi√≥n de Datos"):
    st.markdown("""
    ### Compresi√≥n en Data Warehouses
    
    **Compresi√≥n** reduce el tama√±o de almacenamiento y mejora rendimiento (menos I/O).
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **Tipos de Compresi√≥n:**
        
        **1. Row-level Compression**
        - Comprime filas completas
        - GZIP, LZ4, Snappy
        - Bueno para storage, malo para queries selectivas
        
        **2. Columnar Compression**
        - Comprime cada columna independientemente
        - Mucho m√°s eficiente (valores similares juntos)
        - Dictionary encoding, Run-length encoding
        
        **3. Dictionary Encoding**
        - Sustituye valores repetidos por c√≥digos
        - Perfecto para strings con baja cardinalidad
        - Ejemplo: "Espa√±a" ‚Üí 1, "Francia" ‚Üí 2
        
        **4. Run-Length Encoding (RLE)**
        - Almacena (valor, cuenta) en vez de repetir
        - Ideal para columnas ordenadas
        - Ejemplo: [A,A,A,A,B,B] ‚Üí [(A,4), (B,2)]
        """)
    
    with col2:
        st.success("""
        **Ratios de Compresi√≥n t√≠picos:**
        
        üìä Sin compresi√≥n: 1:1
        
        üìä Row compression: 2-3:1
        
        üìä Columnar compression: 5-10:1
        
        üìä Columnar + ordenamiento: 10-50:1
        
        **Beneficios:**
        
        ‚úÖ Menos storage (cost savings)
        
        ‚úÖ Menos I/O ‚Üí queries m√°s r√°pidas
        
        ‚úÖ M√°s datos en memoria cach√©
        
        ‚úÖ Transferencia de red m√°s r√°pida
        """)

# Materializaci√≥n
with st.expander("üíæ Vistas Materializadas (Materialized Views)"):
    st.markdown("""
    ### Vistas Materializadas
    
    **Vistas Materializadas** pre-calculan y almacenan resultados de queries complejas.
    """)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        **Diferencia con vistas normales:**
        
        | Aspecto | Vista Normal | Vista Materializada |
        |---------|--------------|---------------------|
        | Almacenamiento | Solo definici√≥n SQL | Resultados f√≠sicos |
        | Rendimiento | Ejecuta query cada vez | Instant√°neo |
        | Actualizaci√≥n | Siempre actual | Requiere refresh |
        | Uso de espacio | M√≠nimo | Duplica datos |
        
        **Cu√°ndo usar:**
        - Queries complejas ejecutadas frecuentemente
        - Agregaciones pesadas (SUM, AVG, COUNT)
        - JOINs de muchas tablas
        - Reportes ejecutivos diarios/semanales
        
        **Estrategias de Refresh:**
        - **COMPLETE:** Reconstruye todo
        - **FAST:** Solo cambios incrementales
        - **ON DEMAND:** Manual
        - **ON COMMIT:** Autom√°tico (OLTP)
        - **SCHEDULED:** Cada X horas/d√≠as
        """)
    
    with col2:
        st.code("""
-- Crear vista materializada
CREATE MATERIALIZED VIEW mv_ventas_mensuales
AS
SELECT 
    DATE_TRUNC('month', fecha) as mes,
    producto_id,
    SUM(cantidad) as total_cantidad,
    SUM(importe) as total_importe,
    COUNT(*) as num_transacciones
FROM fact_ventas
GROUP BY 1, 2;

-- Refresh
REFRESH MATERIALIZED VIEW 
mv_ventas_mensuales;

-- Con √≠ndice
CREATE INDEX idx_mv_mes_producto
ON mv_ventas_mensuales(mes, producto_id);
        """, language="sql")

st.divider()

# --- Optimizaci√≥n de Queries ---
st.subheader("üî¨ Optimizaci√≥n de Queries SQL")

tab1, tab2, tab3 = st.tabs(["‚ùå Antipatrones", "‚úÖ Buenas Pr√°cticas", "üìä Ejemplo Optimizaci√≥n"])

with tab1:
    st.markdown("""
    ### Antipatrones comunes que matan el rendimiento
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.error("""
        **1. SELECT * en tablas grandes**
        ```sql
        -- MAL ‚ùå
        SELECT * FROM fact_ventas;
        
        -- BIEN ‚úÖ
        SELECT fecha, producto_id, importe 
        FROM fact_ventas;
        ```
        
        **2. Funciones en WHERE sobre columnas indexadas**
        ```sql
        -- MAL ‚ùå (no usa √≠ndice)
        SELECT * FROM ventas 
        WHERE YEAR(fecha) = 2024;
        
        -- BIEN ‚úÖ (usa √≠ndice)
        SELECT * FROM ventas 
        WHERE fecha >= '2024-01-01' 
          AND fecha < '2025-01-01';
        ```
        
        **3. OR en vez de IN**
        ```sql
        -- MAL ‚ùå
        WHERE pais = 'Espa√±a' 
           OR pais = 'Francia' 
           OR pais = 'Italia';
        
        -- BIEN ‚úÖ
        WHERE pais IN ('Espa√±a', 'Francia', 'Italia');
        ```
        """)
    
    with col2:
        st.error("""
        **4. Subconsultas correlacionadas**
        ```sql
        -- MAL ‚ùå (ejecuta subquery por cada fila)
        SELECT c.nombre,
            (SELECT SUM(importe) FROM ventas v 
             WHERE v.cliente_id = c.cliente_id)
        FROM clientes c;
        
        -- BIEN ‚úÖ (un solo scan)
        SELECT c.nombre, SUM(v.importe)
        FROM clientes c
        LEFT JOIN ventas v ON c.cliente_id = v.cliente_id
        GROUP BY c.nombre;
        ```
        
        **5. DISTINCT innecesario**
        ```sql
        -- MAL ‚ùå (sort caro)
        SELECT DISTINCT cliente_id FROM ventas;
        
        -- BIEN ‚úÖ (si ya es √∫nico)
        SELECT cliente_id FROM ventas 
        GROUP BY cliente_id;
        ```
        
        **6. COUNT(*) cuando solo necesitas EXISTS**
        ```sql
        -- MAL ‚ùå
        IF (SELECT COUNT(*) FROM ventas 
            WHERE cliente_id = 123) > 0
        
        -- BIEN ‚úÖ
        IF EXISTS (SELECT 1 FROM ventas 
                   WHERE cliente_id = 123 LIMIT 1)
        ```
        """)

with tab2:
    st.markdown("""
    ### Buenas pr√°cticas para queries r√°pidas
    """)
    
    st.success("""
    **1. Usa columnas de partici√≥n en WHERE**
    ```sql
    SELECT * FROM ventas
    WHERE fecha BETWEEN '2024-01-01' AND '2024-01-31'  -- Partition pruning
      AND region = 'EU';
    ```
    
    **2. JOIN en el orden correcto (peque√±a ‚Üí grande)**
    ```sql
    SELECT v.*, p.nombre
    FROM dim_producto p  -- Tabla peque√±a primero
    JOIN fact_ventas v ON p.producto_id = v.producto_id
    WHERE p.categoria = 'Electronics';
    ```
    
    **3. Filtra antes de JOINs cuando sea posible**
    ```sql
    SELECT v.*, c.nombre
    FROM (
        SELECT * FROM fact_ventas 
        WHERE fecha >= '2024-01-01'  -- Reduce antes de JOIN
    ) v
    JOIN dim_cliente c ON v.cliente_id = c.cliente_id;
    ```
    
    **4. Usa agregaciones incrementales**
    ```sql
    -- En vez de recalcular todo, usa tablas resumen
    SELECT DATE_TRUNC('month', fecha) as mes,
           SUM(importe)
    FROM ventas_diarias_summary  -- Tabla pre-agregada
    GROUP BY 1;
    ```
    
    **5. Aprovecha CTE (WITH) para legibilidad y reutilizaci√≥n**
    ```sql
    WITH ventas_2024 AS (
        SELECT * FROM ventas WHERE YEAR(fecha) = 2024
    ),
    top_productos AS (
        SELECT producto_id, SUM(importe) as total
        FROM ventas_2024
        GROUP BY producto_id
        ORDER BY total DESC
        LIMIT 10
    )
    SELECT p.nombre, tp.total
    FROM top_productos tp
    JOIN productos p ON tp.producto_id = p.id;
    ```
    """)

with tab3:
    st.markdown("""
    ### Caso real: Optimizaci√≥n de query lenta
    """)
    
    st.code("""
-- QUERY ORIGINAL (lenta: 45 segundos) ‚ùå
SELECT 
    c.nombre_cliente,
    p.nombre_producto,
    SUM(v.cantidad) as total_vendido,
    SUM(v.importe) as ingresos_totales
FROM fact_ventas v
JOIN dim_cliente c ON v.cliente_id = c.cliente_id
JOIN dim_producto p ON v.producto_id = p.producto_id
WHERE v.fecha >= '2023-01-01'
  AND c.pais = 'Espa√±a'
GROUP BY c.nombre_cliente, p.nombre_producto
ORDER BY ingresos_totales DESC;

-- PROBLEMAS:
-- 1. fact_ventas tiene 500M filas, filtra despu√©s de JOIN
-- 2. No usa √≠ndices eficientemente
-- 3. GROUP BY en columnas sin √≠ndice
    """, language="sql")
    
    st.code("""
-- QUERY OPTIMIZADA (r√°pida: 3 segundos) ‚úÖ

-- Paso 1: Pre-filtrar ventas (usa partition pruning)
WITH ventas_filtradas AS (
    SELECT 
        cliente_id,
        producto_id,
        cantidad,
        importe
    FROM fact_ventas
    WHERE fecha >= '2023-01-01'  -- Partition pruning reduce a 50M filas
),

-- Paso 2: Filtrar clientes espa√±oles primero (tabla peque√±a)
clientes_spain AS (
    SELECT cliente_id, nombre_cliente
    FROM dim_cliente
    WHERE pais = 'Espa√±a'  -- Solo 100K clientes en vez de 5M
)

-- Paso 3: JOIN solo con datos filtrados
SELECT 
    cs.nombre_cliente,
    p.nombre_producto,
    SUM(vf.cantidad) as total_vendido,
    SUM(vf.importe) as ingresos_totales
FROM ventas_filtradas vf
JOIN clientes_spain cs ON vf.cliente_id = cs.cliente_id
JOIN dim_producto p ON vf.producto_id = p.producto_id
GROUP BY cs.nombre_cliente, p.nombre_producto
ORDER BY ingresos_totales DESC;

-- MEJORAS APLICADAS:
-- ‚úÖ Partition pruning reduce 10x datos escaneados
-- ‚úÖ Filtra dimensi√≥n antes de JOIN (100K vs 5M)
-- ‚úÖ JOINs sobre datasets reducidos
-- ‚úÖ Usa √≠ndices en claves de JOIN
-- RESULTADO: 15x m√°s r√°pido
    """, language="sql")

st.divider()

# --- Mejores Pr√°cticas ---
st.subheader("‚ú® Mejores Pr√°cticas Generales")

col1, col2 = st.columns(2)

with col1:
    st.success("""
    ### ‚úÖ DO - Hacer
    
    **Dise√±o:**
    - Particionar por fecha (casi siempre)
    - Usar clustering en columnas de filtro frecuentes
    - Implementar vistas materializadas para reportes comunes
    
    **Queries:**
    - Siempre incluir filtros de partici√≥n
    - Seleccionar solo columnas necesarias
    - Usar EXISTS en vez de COUNT cuando aplique
    
    **Mantenimiento:**
    - Analizar estad√≠sticas regularmente (ANALYZE/UPDATE STATISTICS)
    - Monitorear queries lentas
    - Revisar y eliminar √≠ndices no usados
    
    **Datos:**
    - Comprimir tablas grandes
    - Archivar datos antiguos
    - Limpiar datos duplicados
    """)

with col2:
    st.error("""
    ### ‚ùå DON'T - Evitar
    
    **Dise√±o:**
    - No sobre-indexar (cada √≠ndice = overhead en writes)
    - No crear particiones demasiado peque√±as
    - No ignorar el plan de ejecuci√≥n
    
    **Queries:**
    - No usar SELECT * en producci√≥n
    - No aplicar funciones sobre columnas indexadas en WHERE
    - No hacer JOINs sin filtros previos
    
    **Mantenimiento:**
    - No dejar estad√≠sticas desactualizadas
    - No ignorar warnings del optimizer
    - No ejecutar VACUUM/ANALYZE en horas pico
    
    **Datos:**
    - No mezclar datos hot y cold en misma partici√≥n
    - No mantener √≠ndices en datos hist√≥ricos de solo lectura
    """)

st.divider()

# --- Monitoreo ---
with st.expander("üìä Monitoreo de Rendimiento"):
    st.markdown("""
    ### M√©tricas clave a monitorear
    
    **1. Query Performance:**
    - Tiempo de ejecuci√≥n promedio/percentil 95
    - Queries m√°s lentas (top 10)
    - Queries m√°s frecuentes
    - Query plans que hacen full table scans
    
    **2. Recursos:**
    - CPU utilization
    - Memory usage
    - Disk I/O (IOPS)
    - Network throughput
    
    **3. Storage:**
    - Tama√±o de tablas y crecimiento
    - Ratio de compresi√≥n
    - Uso de particiones (skew)
    
    **4. Concurrencia:**
    - Queries concurrentes
    - Queue time (espera)
    - Lock contention
    
    **Herramientas:**
    - **AWS:** CloudWatch + Performance Insights
    - **Snowflake:** Query Profile, Account Usage views
    - **BigQuery:** Query execution details, INFORMATION_SCHEMA
    - **SQL Server:** Query Store, DMVs
    """)

st.divider()

# --- Ejemplo Final ---
with st.expander("üí° Caso de estudio completo"):
    st.markdown("""
    ### Optimizaci√≥n real: E-commerce con 100TB de datos
    
    **Situaci√≥n inicial:**
    - Tabla fact_orders: 50 mil millones de filas
    - Reportes diarios: 30 minutos
    - An√°lisis ad-hoc: imposibles
    - Costo cloud: $50K/mes
    
    **Optimizaciones aplicadas:**
    
    **1. Particionamiento por fecha (d√≠a)**
    - Antes: Full table scan 50B filas
    - Despu√©s: Scan de 1 d√≠a = 150M filas
    - **Mejora: 300x**
    
    **2. Clustering por (fecha, customer_country)**
    - Mejora compresi√≥n: 5:1 ‚Üí 12:1
    - Reduce I/O en queries de pa√≠s espec√≠fico
    - **Mejora: 2.4x adicional**
    
    **3. Vistas materializadas para reportes diarios**
    - Pre-agrega daily_sales, daily_customers
    - Refresh incremental cada hora
    - **Mejora: Reportes de 30 min ‚Üí 10 segundos**
    
    **4. Columnstore indexes en dimensiones**
    - dim_product, dim_customer
    - JOINs 5x m√°s r√°pidos
    
    **5. Reescritura de queries top 10**
    - Aplicar mejores pr√°cticas SQL
    - Filtros antes de JOINs
    - **Mejora: 10-50x por query**
    
    **Resultados:**
    - Reportes: 30 min ‚Üí 10 seg (180x m√°s r√°pido)
    - An√°lisis ad-hoc: Ahora factibles (1-5 min)
    - Costo cloud: $50K ‚Üí $18K/mes (64% reducci√≥n)
    - Satisfacci√≥n usuarios: ‚≠ê‚≠ê ‚Üí ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
    """)

st.divider()

